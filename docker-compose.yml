version: '3.8'

services:
  # Qdrant 벡터 데이터베이스
  qdrant:
    image: qdrant/qdrant:latest
    container_name: ex-gpt-qdrant
    ports:
      - "6333:6333"
    volumes:
      - ./data/qdrant:/qdrant/storage
    restart: unless-stopped
    environment:
      - QDRANT_LOG_LEVEL=INFO

  # VLM 임베딩 서버 (포트 8100)
  vllm-embeddings:
    image: vllm/vllm-openai:latest
    container_name: ex-gpt-embeddings
    command:
      - --served-model-name
      - default-model
      - --model
      - Qwen/Qwen3-Embedding-0.6B
      - --task
      - embed
    ports:
      - "8100:8000"
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    environment:
      - HF_TOKEN=${HF_TOKEN}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['4']
              capabilities: [gpu]
    restart: unless-stopped

  # Reranker 서버 (포트 8101)
  vllm-rerank:
    image: vllm/vllm-openai:latest
    container_name: ex-gpt-rerank
    command:
      - --served-model-name
      - default-model
      - --model
      - BAAI/bge-reranker-v2-m3
      - --task
      - score
    ports:
      - "8101:8000"
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    environment:
      - HF_TOKEN=${HF_TOKEN}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['5']
              capabilities: [gpu]
    restart: unless-stopped

  # LLM 추론 서버 (포트 8000)
  vllm:
    image: vllm/vllm-openai:latest
    container_name: ex-gpt-llm
    command:
      - --served-model-name
      - default-model
      - --model
      - Qwen/Qwen3-32B
      - --tensor-parallel-size
      - "2"
      - --gpu-memory-utilization
      - "0.9"
    ports:
      - "8000:8000"
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    environment:
      - HF_TOKEN=${HF_TOKEN}
      - CUDA_VISIBLE_DEVICES=6,7
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['6', '7']
              capabilities: [gpu]
    restart: unless-stopped

  # ex-GPT API 서버
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ex-gpt-api
    ports:
      - "8080:8000"
    volumes:
      - ./src:/app/src
      - ./uploads:/app/uploads
      - ./processed:/app/processed
      - ./temp:/app/temp
      - ./cache:/app/cache
      - ./logs:/app/logs
    environment:
      - CHAT_MODEL_ENDPOINT=http://vllm:8000/v1
      - CHAT_MODEL_NAME=default-model
      - EMBEDDING_MODEL_ENDPOINT=http://vllm-embeddings:8000/v1
      - EMBEDDING_MODEL_NAME=default-model
      - RERANK_MODEL_ENDPOINT=http://vllm-rerank:8000/v1
      - RERANK_MODEL_NAME=default-model
      - QDRANT_URL=http://qdrant:6333
      - FLAGS__ENABLE_VLM=True
      - FLAGS__ENABLE_RERANK=True
      - FLAGS__ENABLE_FILE_CONTEXT_GENERATION=True
      - SEARCH__RETRIEVER_MAX_DOCUMENTS=10
      - SEARCH__RERANKER_MAX_DOCUMENTS=10
    depends_on:
      - qdrant
      - vllm
      - vllm-embeddings
      - vllm-rerank
    restart: unless-stopped

  # 관리도구 UI
  admin-ui:
    build:
      context: .
      dockerfile: Dockerfile.admin
    container_name: ex-gpt-admin
    ports:
      - "5000:5000"
    volumes:
      - ./src:/app/src
      - ./uploads:/app/uploads
      - ./processed:/app/processed
      - ./temp:/app/temp
    environment:
      - API_ENDPOINT=http://api:8000
    depends_on:
      - api
    restart: unless-stopped

  # MinIO (S3 호환 저장소)
  minio:
    image: minio/minio:latest
    container_name: ex-gpt-minio
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - ./data/minio:/data
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=admin123456
    command: server /data --console-address ":9001"
    restart: unless-stopped

  # Redis (캐시)
  redis:
    image: redis:alpine
    container_name: ex-gpt-redis
    ports:
      - "6379:6379"
    volumes:
      - ./data/redis:/data
    restart: unless-stopped

  # PostgreSQL (메타데이터 저장)
  postgres:
    image: postgres:14-alpine
    container_name: ex-gpt-postgres
    ports:
      - "5432:5432"
    volumes:
      - ./data/postgres:/var/lib/postgresql/data
    environment:
      - POSTGRES_DB=exgpt
      - POSTGRES_USER=exgpt
      - POSTGRES_PASSWORD=exgpt123
    restart: unless-stopped

volumes:
  qdrant-data:
  minio-data:
  redis-data:
  postgres-data:
  huggingface-cache:

networks:
  default:
    name: ex-gpt-network
    driver: bridge
